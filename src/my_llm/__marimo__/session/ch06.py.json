{
  "version": "1",
  "metadata": {
    "marimo_version": "0.18.4"
  },
  "cells": [
    {
      "id": "setup",
      "code_hash": "a39c6b70485d7acc0e8add2403824615",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stderr",
          "text": "2025-12-31 09:07:23.251009: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n/home/applejxd/src/my-llm/.venv/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n  if not hasattr(np, \"object\"):\n",
          "mimetype": "text/plain"
        },
        {
          "type": "stream",
          "name": "stdout",
          "text": "matplotlib version: 3.10.8\nnumpy version: 2.3.5\ntiktoken version: 0.12.0\ntorch version: 2.9.1+cu128\ntensorflow version: 2.20.0\nDevice: cuda\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "Hbol",
      "code_hash": "e086b2e2afa39a596a0afbc7ddb57aad",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h1 id=\"chapter-6-finetuning-for-text-classification\">Chapter 6: Finetuning for Text Classification</h1></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "MJUe",
      "code_hash": "06790705e4dbb08d0cde3cf6c778be6a",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Show library versions.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "vblA",
      "code_hash": "a23c65ed3cff18e4c57c71c8b6075001",
      "outputs": [],
      "console": []
    },
    {
      "id": "bkHC",
      "code_hash": "d82b06ff579c1f8271bb8b38d184f756",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h2 id=\"62-preparing-the-dataset\">6.2 Preparing the dataset</h2></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "Xref",
      "code_hash": "6e5b7aa2f81993ad83c3b256a3b766ee",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Define a function to download, extract, and rename a dataset.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "SFPL",
      "code_hash": "16c31b02d328a35e5043cad4a8b90c7d",
      "outputs": [],
      "console": []
    },
    {
      "id": "lEQa",
      "code_hash": "3de5512fec946f8a7f61f0f14ad97b57",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Set paths to download dataset for fine-tuning.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "PKri",
      "code_hash": "1d798d0eba7525796634328ec7222314",
      "outputs": [],
      "console": []
    },
    {
      "id": "BYtC",
      "code_hash": "835d13770f62b52c44344509e0cfecb1",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Prepare dataset by using the above function</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "RGSE",
      "code_hash": "83ca7e320c467331c259c50f273f82b7",
      "outputs": [],
      "console": []
    },
    {
      "id": "Kclp",
      "code_hash": "2b2afa17a88e153f03b6df70ced9e44b",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">This dataset has Tab separater without header. Each rows are the pair of spam/ham pair and corresponding text (message). The ham means not spam.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "emfo",
      "code_hash": "66416f320a7510b859ba888d4b02135c",
      "outputs": [],
      "console": []
    },
    {
      "id": "Hstk",
      "code_hash": "39cc5323b2cacd7aac204ea552cf5825",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Show the statistics. Spam messages are anomalous and its number is much smallear than ham messages.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "nWHF",
      "code_hash": "7a675c919eeb24c97485e218990c90ae",
      "outputs": [],
      "console": []
    },
    {
      "id": "iLit",
      "code_hash": "54134b834ba6f17b726c5f67f47ea5cf",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Undersample to balance the number of spam and ham</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "ZHCJ",
      "code_hash": "29591c9c19a02f29ebb37d9ec80bc39b",
      "outputs": [],
      "console": []
    },
    {
      "id": "ROlb",
      "code_hash": "2095d9be11801b30bdb157ee49dc7c69",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Execute and check the result</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "qnkX",
      "code_hash": "bdb3279c7ac0422e69454a75d9cba7be",
      "outputs": [],
      "console": []
    },
    {
      "id": "TqIu",
      "code_hash": "1840a2207df2ae92ea58a767a467bc70",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Mapping <code>str</code> to <code>int</code> for numerical operations</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "Vxnm",
      "code_hash": "6572ac0821989a0b15a68637eb75433a",
      "outputs": [],
      "console": []
    },
    {
      "id": "DnEU",
      "code_hash": "2545c68edb32e1227cd6ab21dbd9f816",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Create splits for training, validation, and testing.\nFor <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html\" rel=\"noopener noreferrer\" target=\"_blank\">pandas.DataFrame.sample</a>, the <code>frac=1</code> means 100% sampling, and the <code>.reset_index(drop=True)</code> means the operation delete the original index (row number).</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "ulZA",
      "code_hash": "324a5aebef1bbc06a7e8113f25d92ea2",
      "outputs": [],
      "console": []
    },
    {
      "id": "ecfG",
      "code_hash": "8bf02b4147a864bffab3cddc9cce47d8",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Create the splits with the ratio for</span>\n<marimo-tex class=\"arithmatex\">||[\n\\text{train} : \\text{valid} : \\text{test} = 0.7 : 0.1 : 0.2\n||]</marimo-tex><span class=\"paragraph\">and save these dataframes as CSV</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "Pvdt",
      "code_hash": "5f20ca91572d694180d0087e522bfbf4",
      "outputs": [],
      "console": []
    },
    {
      "id": "ZBYS",
      "code_hash": "25582cc49ef31db6110136c573ab55ee",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h2 id=\"63-creating-data-loaders\">6.3 Creating data loaders</h2></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "aLJB",
      "code_hash": "30725203dbcfde8e530dbdb4f031ebf6",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Get tiktoken encoder and the token ID for <code>&lt;|endoftext|&gt;</code> to use it as padding token ID</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "nHfw",
      "code_hash": "9ca35c0a9733b6e6df6372e9311354d2",
      "outputs": [],
      "console": []
    },
    {
      "id": "xXTn",
      "code_hash": "57ce85a77d758d8a2211e7ef78325656",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Define <a href=\"https://docs.pytorch.org/docs/stable/data.html#map-style-datasets\" rel=\"noopener noreferrer\" target=\"_blank\">Map-style datasets</a> for use with a DataLoader.\nToken sequences are padded to a uniform length, either specified explicitly or set to the maximum sequence length in the dataset.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "AjVT",
      "code_hash": "bfdb861ddf28020baf59674442bf8b0a",
      "outputs": [],
      "console": []
    },
    {
      "id": "pHFh",
      "code_hash": "f9fd8c26de18e3bdafdf32ba1c89f8cf",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Construct a dataset for training. We can set the <code>max_length</code> to our context length to ensure it.\nAfter the creation, check the <code>max_length</code> and the shape of each data.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "NCOB",
      "code_hash": "247029de2eec7369cb951326898e2f02",
      "outputs": [],
      "console": []
    },
    {
      "id": "aqbW",
      "code_hash": "58fc08bec92d34f42a58c34e3e374927",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Create validation and test datasets also. We share the <code>max_length</code> for each construction to ensure the same condition.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "TRpd",
      "code_hash": "6a3f68b3d7ab8466e90aafb4df630d3d",
      "outputs": [],
      "console": []
    },
    {
      "id": "TXez",
      "code_hash": "97952fe2c0bd38c38e306520172f39e5",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Construct <a href=\"https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\" rel=\"noopener noreferrer\" target=\"_blank\">daloaders</a> by using the datasets</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "dNNg",
      "code_hash": "a1d68ba7e509be48ac418992316f884e",
      "outputs": [],
      "console": []
    },
    {
      "id": "yCnT",
      "code_hash": "6757407824728e3ecdb69b739686d2e3",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Iterate entirely for training dataloader to get the final batch and check the shape. We can see surely the final batch is complete shape.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "wlCL",
      "code_hash": "294e0a169f859d04b92a058160caf957",
      "outputs": [],
      "console": []
    },
    {
      "id": "kqZH",
      "code_hash": "f13efb792677df8b1fe9cb42a1e6d3c5",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Check the number of batches for each dataloaders</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "wAgl",
      "code_hash": "abe409bee04adc5b5b609d8e940afc20",
      "outputs": [],
      "console": []
    },
    {
      "id": "rEll",
      "code_hash": "725ef011f8e167b571213c85d8cfea91",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h2 id=\"64-initializing-a-model-with-pretrained-weights\">6.4 Initializing a model with pretrained weights</h2></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "dGlV",
      "code_hash": "88f27c70f17c11d2ca30a0b3a0e5faee",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Use the same configuration of the model with the pretraining</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "SdmI",
      "code_hash": "0516e8719f6343bf92fc32fa13d995b1",
      "outputs": [],
      "console": []
    },
    {
      "id": "lgWD",
      "code_hash": "8f4fb5bea69c3bb5fcb8dbafaf016d9b",
      "outputs": [],
      "console": []
    },
    {
      "id": "yOPj",
      "code_hash": "d4d40d2df60eb0a9077a348e6789f0c5",
      "outputs": [],
      "console": []
    },
    {
      "id": "fwwy",
      "code_hash": "8ab82540d736d64b8a2f5b170f45f4c6",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Check the model is pretrained and its inference is proper by using a simple sequence</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "LJZf",
      "code_hash": "ff98e6024183347ecd2cc09f3c35c08c",
      "outputs": [],
      "console": []
    },
    {
      "id": "urSm",
      "code_hash": "db4f3899674cd698b10e785ef81e1c8c",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">See the behavior before the fine-tuning. The answer does not follow the initial instructions, and answer the question without yes or no.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "jxvo",
      "code_hash": "e7412464297d442156f78159dabd5a78",
      "outputs": [],
      "console": []
    },
    {
      "id": "mWxS",
      "code_hash": "c746ef96ec77ad687a54136b96fcea38",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h2 id=\"65-adding-a-classification-head\">6.5 Adding a classification head</h2></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "CcZR",
      "code_hash": "60a052d9cd7b2720a739253c41fb838e",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Freeze all layers initially to reuse the most of weights</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "YWSi",
      "code_hash": "2e34afdc68235ce1c63953b4963c2a3a",
      "outputs": [],
      "console": []
    },
    {
      "id": "zlud",
      "code_hash": "73c7a0fa7a80cc2409673fc1469e0736",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Define new linear layer to classify spam or ham, and replace the current last layer to output expected tokens with the new linear layer</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "tZnO",
      "code_hash": "01f5a825e1fd4faae90dab75e0aff043",
      "outputs": [],
      "console": []
    },
    {
      "id": "xvXZ",
      "code_hash": "4aa29009c67f5843084cb6a18d91f1b2",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Allow gradient calculations for the transformer blocks and the last <code>LayerNorm</code> module to train</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "CLip",
      "code_hash": "c93177d9a96880664874b629c251184b",
      "outputs": [],
      "console": []
    },
    {
      "id": "YECM",
      "code_hash": "7a5b380fcbd3084089bec4888cb148df",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Try inference with this architecture before fine-tuning by using following inputs</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "cEAS",
      "code_hash": "52d4bc4b7c6a69ef985662603319fa5a",
      "outputs": [],
      "console": []
    },
    {
      "id": "iXej",
      "code_hash": "21894176d09b211197689c7796347191",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">The output size is <marimo-tex class=\"arithmatex\">||((\\text{batch size}, \\text{num tokens}, \\text{num classes})||)</marimo-tex>.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "EJmg",
      "code_hash": "4d27e30debe471ab2627b9367d533760",
      "outputs": [],
      "console": []
    },
    {
      "id": "UmEG",
      "code_hash": "96c6cefabb03eebe1001c7c6f9844cbd",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">We use the classification result for the last token only because this is the only token can have causal correlation with all tokens based on causal attention mask.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "vEBW",
      "code_hash": "c1e604ebd9acd700803b2f019ee1f7d5",
      "outputs": [],
      "console": []
    },
    {
      "id": "kLmu",
      "code_hash": "e53df0cda770efd42b5edc76f5ac1b68",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h2 id=\"66-calculating-the-classification-loss-and-accuracy\">6.6 Calculating the classification loss and accuracy</h2></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "IpqN",
      "code_hash": "e09ad367ef66dde02f3e09a289021bef",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Map the output to class label</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "dxZZ",
      "code_hash": "9f29686e00104b281f7b6adfe6f18c79",
      "outputs": [],
      "console": []
    },
    {
      "id": "dlnW",
      "code_hash": "9c5c1031b921d40a421e24fa7e582798",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">We can get the same result by just taking <code>argmax</code> only because <code>softmax</code> is monotonic</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "TTti",
      "code_hash": "48c6dd89eb927e440d08a4ab79dc8d17",
      "outputs": [],
      "console": []
    },
    {
      "id": "RKFZ",
      "code_hash": "57467ab57148249f353197313d307e57",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Define the accuracy metric to evaluate</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "IaQp",
      "code_hash": "d96917d13fc51f6ec4be65b603f213fe",
      "outputs": [],
      "console": []
    },
    {
      "id": "IWgg",
      "code_hash": "fecdc2859c7ec7853a0ff41a16fccbbc",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Compute initial accuracies without training</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "fCoF",
      "code_hash": "d7588b93de4975a0503cb5c921c625c0",
      "outputs": [],
      "console": []
    },
    {
      "id": "LkGn",
      "code_hash": "6cabb9925b7c834edfa6e567bd5080dc",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Use cross entropy loss to train instead of the accuracy because of these differentiability. See <a href=\"https://docs.pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss\" rel=\"noopener noreferrer\" target=\"_blank\">this</a> for the definition.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "zVRe",
      "code_hash": "d8bf5f9cc5e9e234f8ac4cbe3e184fe4",
      "outputs": [],
      "console": []
    },
    {
      "id": "woaO",
      "code_hash": "8f634619be3c3d23e1bbef2238b82ebe",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Compute average loss by using each dataloader</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "HnMC",
      "code_hash": "faffc3fac75277f366b70825dcce25ca",
      "outputs": [],
      "console": []
    },
    {
      "id": "wadT",
      "code_hash": "477a0fd1bef6b836bb96d01230ab2d62",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Compute initial losses without training</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "VCRE",
      "code_hash": "a39628cff41031cb506c2af868148105",
      "outputs": [],
      "console": []
    },
    {
      "id": "hgqU",
      "code_hash": "02f21861c1d12c8f039e5fab5f04281c",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h2 id=\"67-finetuning-the-model-on-supervised-data\">6.7 Finetuning the model on supervised data</h2></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "PSUk",
      "code_hash": "ebc388729025c324ec9cdb5c54195bd9",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Define fine-tuning trainer that calculates accuracies in the end of each epochs</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "mfOT",
      "code_hash": "5843e94020eee2de36611a59edcff879",
      "outputs": [],
      "console": []
    },
    {
      "id": "vGiW",
      "code_hash": "06add10f724d1c9658481fc671c9efb1",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Define fine-tuning evaluater</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "SYQT",
      "code_hash": "ab696f5f5a473364028033f86fcd143f",
      "outputs": [],
      "console": []
    },
    {
      "id": "bMrW",
      "code_hash": "82e6288828484c769313cc5bae231e72",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Execute the training in 5 epochs, and the accuracy will be improved more than 90%. It takes about 3 minuites for RTX3070.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "PSQn",
      "code_hash": "a09e1c0c5298b68a395c975e109dc86b",
      "outputs": [],
      "console": []
    },
    {
      "id": "OfTS",
      "code_hash": "2ec0807e0078d3ad3a990cc721b7da67",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Plot the losses and verify it works well from the fact that losses decrease rapidlly. Especially, validation losses looks like training losses and it shows the traning avoids overfitting. These facts justify 5 epochs are enough for this fine-tuning.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "lQxp",
      "code_hash": "1781d14199ed28c42b5f860f313ff973",
      "outputs": [],
      "console": []
    },
    {
      "id": "Plbk",
      "code_hash": "9cd3f1c934a5d7b29da11fe452ae550e",
      "outputs": [],
      "console": []
    },
    {
      "id": "rSYo",
      "code_hash": "9f470fad69b4018691a04a2ca0857d23",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Plot the accuracies also. We used 5 bathes to evaluate these (see the <code>eval_iter</code> argument).</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "HuZB",
      "code_hash": "cd7635159c67382a1c2cf7e3dcd2d016",
      "outputs": [],
      "console": []
    },
    {
      "id": "WfYj",
      "code_hash": "e1f4a9645bc0d544a0763addfe68bb48",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">The results for the final model and entire dataloader show the accuracies are higher than 90%. The fact that the test accuracy is smaller than others shows small overfitting. This differences may be removed by hyper parameter tuning for <code>drop_rate</code>, <code>weight_decay</code>, and so on.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "Ynfw",
      "code_hash": "3cf9573faf73fae5b6ad732800d221a3",
      "outputs": [],
      "console": []
    },
    {
      "id": "LqFA",
      "code_hash": "efdb944746da6f69fb00a237e9f8a5be",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h2 id=\"68-using-the-llm-as-a-spam-classifier\">6.8 Using the LLM as a spam classifier</h2></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "uDnK",
      "code_hash": "de094639d12304f759efa11e710759ce",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Define a function to do preprocessing, inference, and postprocessing to answer whether the input text is spam or ham</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "aWBL",
      "code_hash": "cc5bd24b89f7ed6614e245e54d901392",
      "outputs": [],
      "console": []
    },
    {
      "id": "MIsd",
      "code_hash": "67d46a28f54d5a34c7975c3cd7b3b45a",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">This is an example for spam</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "IrqS",
      "code_hash": "ac8892284432db26a0443e1ea384dee3",
      "outputs": [],
      "console": []
    },
    {
      "id": "Lpqv",
      "code_hash": "c336bb25f217d86a71a6b5d507259ab8",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">This is an example for ham</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "upgv",
      "code_hash": "39cb8b8849097d33b2a3b51881707fe9",
      "outputs": [],
      "console": []
    },
    {
      "id": "WJUG",
      "code_hash": "c6a26b4572ecc7b1a5e006617aeef6a0",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">We can save the result for the fine-tuning by this</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "pCao",
      "code_hash": "bcab5c6df961a455c03c96cd0a524586",
      "outputs": [],
      "console": []
    },
    {
      "id": "wEIy",
      "code_hash": "c9d78b37c69088e0d2fa15ed955ff555",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">And load the model by this</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "wlyU",
      "code_hash": "55a8f3b487857b55f7c7453b548d069c",
      "outputs": [],
      "console": []
    },
    {
      "id": "PieA",
      "code_hash": null,
      "outputs": [],
      "console": []
    }
  ]
}