{
  "version": "1",
  "metadata": {
    "marimo_version": "0.18.4"
  },
  "cells": [
    {
      "id": "Hbol",
      "code_hash": "356c566b8e57516ed4dbea29c5388573",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h1 id=\"chapter-3-coding-attention-mechanisms\">Chapter 3: Coding Attention Mechanisms</h1></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "vblA",
      "code_hash": "1b72de0e56ac0f117e6e6df8195f0789",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h2 id=\"33-attending-to-different-parts-of-the-input-with-self-attention\">3.3 Attending to different parts of the input with self-attention</h2></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "bkHC",
      "code_hash": "e6d4c34d291262167f7fd630fd51f17e",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h3 id=\"331-a-simple-self-attention-mechanism-without-trainable-weights\">3.3.1 A simple self-attention mechanism without trainable weights</h3></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "lEQa",
      "code_hash": "4ecdd60550fc95574f958fec3932c248",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Prepare embedded vectors as inputs to attention layers.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "Xref",
      "code_hash": "a0c210f2a0721e6d4c4b53078999e77f",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Attenstion score <marimo-tex class=\"arithmatex\">||(\\omega_{2i}||)</marimo-tex> is defined as\n$$\n\\vec{\\omega}_{2i} \\equiv \\vec{x}_2 \\cdot \\vec{x}_i.\n$$</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "BYtC",
      "code_hash": "8cc4d5403ad6581e162fe069f8a90c29",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">This is a verification of dot product for beginners by\n$$\n\\vec{x}<em>0\\cdot\\vec{x}_1\\equiv\\sum</em>{i=0}^{\\mathrm{dim}(\\vec{x}_0)}(x_0)_i(x_1)_i.\n$$\nThe dot product has meaning of similarity between two vectors.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "Kclp",
      "code_hash": "bef957f8fa5ba9de673528083ce46430",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">The attention should be normalized to represents weights.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "Hstk",
      "code_hash": "15e9e2fffafd9fbec97dc15aff923e36",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">More suitable function for normalization is the softmax function that has positive values and robust gradient for traning\n$$\n\\sigma(x_i;\\vec{x})\\equiv\\frac{e^{x_i}}{\\sum_j e^{x_j}}.\n$$</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "iLit",
      "code_hash": "c8f5a9fac3ab502b245a1c4f3008d817",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">The softmax function also leads weights whose total is 1.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "ROlb",
      "code_hash": "fd4c9039872fafbdd63653ce5fe2325f",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">PyTorch softmax function is more stable with respect to numerical errors because it uses <a href=\"https://discuss.pytorch.org/t/justification-for-logsoftmax-being-better-than-log-softmax/140130/3\" rel=\"noopener noreferrer\" target=\"_blank\">max-trick and LogSumExp trick</a>.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "TqIu",
      "code_hash": "4a1e95210a8d2650d158b2663e404299",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">The attention scores are used as weights for weighted average of embedded vectors.\nThe result is called as context vectors <marimo-tex class=\"arithmatex\">||(\\vec{z}^{(i)}||)</marimo-tex>.</span>\n<span class=\"paragraph\">Formaly, the context vectors <marimo-tex class=\"arithmatex\">||(\\vec{z}^{(i)}||)</marimo-tex> are defined as\n$$\n\\vec{z}^{(i)}\n\\equiv\\sum_j\\mathrm{Softmax}<em>j(\\omega</em>{ij})\\vec{x}<em>j\n\\equiv\\frac{\\sum_j\\omega</em>{ij}\\vec{x}<em>j}{\\sum_k\\omega</em>{ik}}\n\\equiv\\frac{(\\sum_j\\vec{x}_j\\vec{x}_j^T)\\vec{x}_i}{\\sum_k\\vec{x}_k\\cdot\\vec{x}_i}\n$$</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "DnEU",
      "code_hash": "a4847ec0a2934b837c4d8285d9636c51",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h3 id=\"332-computing-attention-weights-for-all-input-tokens\">3.3.2 Computing attention weights for all input tokens</h3></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "ulZA",
      "code_hash": "7230e61f3e5b41e543c00e367b2d5838",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Calculate context vectors with respect to all query vectors.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "Pvdt",
      "code_hash": "a607bd81dc431c54bcedb110e5407a15",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">In Python, such double for-loops are inefficient. The following matrix product is preferred for computation efficiency. This result is the same with the result of the previous cell.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "aLJB",
      "code_hash": "8815bafad990234ae36eec3e5c1dc746",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">We can apply softmax function to each rows.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "xXTn",
      "code_hash": "32daaa92469d6bf75d5eb6b77a77751f",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">The normalization is verified by this.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "pHFh",
      "code_hash": "554c86000db51fe8d8c440887f0e6847",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Weighted averages are also simplified by using matrix-vector products.\nFinally, we obtain the following formula:\n$$\nZ\\equiv\\mathrm{Softmax}(XX^T)X\n$$</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "aqbW",
      "code_hash": "b474df4ce89eec717e1844456c3fef54",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">The 2nd slice is the exactly same with the result of the previous section.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "TXez",
      "code_hash": "b63f1b7cd636c0ab92ce784323a145c4",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h2 id=\"34-implementing-self-attention-with-trainable-weights\">3.4 Implementing self-attention with trainable weights</h2></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "dNNg",
      "code_hash": "c6405f6ef21ed490604fe1accb5aadb9",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h3 id=\"341-computing-the-attention-weights-step-by-step\">3.4.1 Computing the attention weights step by step</h3></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "yCnT",
      "code_hash": "b221b970b84206a7e7d0f3720392b136",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Use these inputs and parameters to show how to introduce trainable attention layer.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "kqZH",
      "code_hash": "64582f38215fdaef16ce338fd647579b",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">These are trainable weight matricies (or linear projections).</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "rEll",
      "code_hash": "faddb0748ea709832a0c599e42044372",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">The linear projection are like these\n$$\nQ_2\\equiv \\vec{x}_2 W^Q ,\\quad\nK_2\\equiv \\vec{x}_2 W^K,\\quad\nV_2\\equiv \\vec{x}_2 W^V,\n$$</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "SdmI",
      "code_hash": "ce116d1a8afeb02038a2ef38dab7fb66",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Linear projection for all inputs are\n$$\nK=XW^K, V=XW^V.\n$$</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "yOPj",
      "code_hash": "8425abd660941ebfbcf4854c753a222e",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">The attention score <marimo-tex class=\"arithmatex\">||(\\omega_{22}\\equiv Q_2\\cdot K_2||)</marimo-tex> is this.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "LJZf",
      "code_hash": "6a99a6019b551355313b8454ca548f8e",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Scores for all keys are calculated by <marimo-tex class=\"arithmatex\">||(\\omega_2\\equiv Q_2 K||)</marimo-tex>.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "jxvo",
      "code_hash": "2b230a782e39bd6d198910008becbca7",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Take the attention scores by Scaled Dot-Product Attention way.\nThe attention score is scaled by square root of the dimension of keys like\n$$\n\\alpha_2\\equiv\\mathrm{Softmax}\\frac{\\omega_2}{\\sqrt{\\mathrm{dim}(K_i)}}\n$$</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "CcZR",
      "code_hash": "28021fa9d228d4bc2dcb9f772c1154e7",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Finally, we get trainable context vector as\n$$\n\\vec{z}^2\\equiv\\mathrm{Softmax}\\left(\\frac{Q_2K}{\\sqrt{\\mathrm{dim}(K_i)}}\\right)V.\n$$</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "zlud",
      "code_hash": "7cd1c33c5e9d4edaa4e095c5f8bc4db8",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h3 id=\"342-implementing-a-compact-selfattention-class\">3.4.2 Implementing a compact SelfAttention class</h3></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "xvXZ",
      "code_hash": "71a30beabb5fb21930dfc17c9daeeef3",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">The trainable context vectors are calculated by this instance. The 2nd slice of the result is the same with the result of the previous section.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "YECM",
      "code_hash": "841d804357b2a390dac971bb3280646b",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">By using <code>nn.Linear</code>, the class definition is more simplified and more stable because of a good initialization scheme called as <a href=\"https://docs.pytorch.org/docs/stable/nn.init.html#torch.nn.init.kaiming_uniform_\" rel=\"noopener noreferrer\" target=\"_blank\">the Kaiming Uniform initialization</a>.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "iXej",
      "code_hash": "9f88dca8b8156f32cc4925bcac5e18f1",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">This output is different with the previous results because of such initialization schemes.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "UmEG",
      "code_hash": "8bf3ac6400f1ff6082dab26d161ab918",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h2 id=\"35-hiding-future-words-with-causal-attention\">3.5 Hiding future words with causal attention</h2></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "vEBW",
      "code_hash": "57c511ce00e971f7be359be966819ceb",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h3 id=\"351-applying-a-causal-attention-mask\">3.5.1 Applying a causal attention mask</h3></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "kLmu",
      "code_hash": "aa7e4b02aa0288ed425038ca02e54c17",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">This is an initial attention weights like previous.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "dxZZ",
      "code_hash": "afc1416a20a22e1bbf523a288e02b85c",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Let's mask the upper right of it to ensure causal token prediction tasks.\nSuch binary mask is easily created by <code>torch.tril</code>.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "TTti",
      "code_hash": "444d50edf93def25bb0fb23ddd306f33",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">The masking is simple multiplication of these <marimo-tex class=\"arithmatex\">||(W_a\\mathbb{1}_{i\\geq j}||)</marimo-tex>.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "IaQp",
      "code_hash": "4955678db132bc3de765fb3feaa099e7",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Normalize each rows to use it as weights. The normalization should be done after the masking to prevent data leak from futures.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "fCoF",
      "code_hash": "3ab7ecedefc7269da93d6e3beaf4205c",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">For more efficiency, this masking is replaced by filling <code>-inf</code> to upper right of attention scores before taking Softmax.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "zVRe",
      "code_hash": "e3421f9caf20181d4d21929c376b0742",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\"><marimo-tex class=\"arithmatex\">||(\\exp(-\\infty)=0||)</marimo-tex> leads the same result with the masking.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "HnMC",
      "code_hash": "b251d41af776af72e8ff16cba385925b",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h3 id=\"352-masking-additional-attention-weights-with-dropout\">3.5.2 Masking additional attention weights with dropout</h3></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "wadT",
      "code_hash": "5acd40cccb5ab0b77ce60820056c8db1",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">We introduct dropout to prevent overfitting to specific tokens. We drop 50% of elements and the remaining values are doubled to keep the total scale. This dropout layer is applied only for training.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "hgqU",
      "code_hash": "2e5d4b307962790c9bb8cac1778ce7ab",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">The dropout layer is applied after attention weights are calculated.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "mfOT",
      "code_hash": "fc8ed30bfdf2007d29e2ee5c58f10cc0",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h3 id=\"353-implementing-a-compact-causal-self-attention-class\">3.5.3 Implementing a compact causal self-attention class</h3></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "vGiW",
      "code_hash": "370c21f9e8ac28cf72329e5926808ab7",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">We introduce such causal attention, dropout, and batch inference to attention layer. The batch input for testing is as follows.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "bMrW",
      "code_hash": "451d1c657edd1be831d2e531ffb1845b",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">This is an example for causal attention layer. <a href=\"https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_buffer\" rel=\"noopener noreferrer\" target=\"_blank\"><code>register_buffer</code></a> is used to define constant (non-trained) parameters and ensure it is allocated on suitable device.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "OfTS",
      "code_hash": "cf48c59b8820e6b4ac72bee6f5575f52",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">This is an example to use the forward path. Check the input and output shapes.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "Plbk",
      "code_hash": "6a633c1e552821a320f3a8ccde69baac",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h2 id=\"36-extending-single-head-attention-to-multi-head-attention\">3.6 Extending single-head attention to multi-head attention</h2></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "rSYo",
      "code_hash": "f743c24923cb102829cb8d88ecbbdb2c",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h3 id=\"361-stacking-multiple-single-head-attention-layers\">3.6.1 Stacking multiple single-head attention layers</h3></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "HuZB",
      "code_hash": "bf56d8bf893de06c4814455909aff84b",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Let's extend the attention layer to multi-head. This is a naive extetion from single-head one.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "Ynfw",
      "code_hash": "74de8b12717dac7c4047362a9e77c603",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">The output shape is <marimo-tex class=\"arithmatex\">||((B,N,d_{out}\\times2)||)</marimo-tex>.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "uDnK",
      "code_hash": "d47cb323919be524729487e24e60f574",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h3 id=\"362-implementing-multi-head-attention-with-weight-splits\">3.6.2 Implementing multi-head attention with weight splits</h3></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "aWBL",
      "code_hash": "87280c496fc98980d01ab0d04ff7b979",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><span class=\"paragraph\">Simplify the multi-head attention layer by self-contained way and avoid loops by using matrix products.</span></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "setup",
      "code_hash": "f80cd351b905c364088fa51d0559db39",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": []
    },
    {
      "id": "MJUe",
      "code_hash": "ac76a1258bd3ba7aa8436da2d786332e",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "torch version: 2.9.1+cu128\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "PKri",
      "code_hash": "47255886eacf9cf4f4a947a0778c9134",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": []
    },
    {
      "id": "SFPL",
      "code_hash": "577bdd9505b0d5e67c0217711991718b",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "RGSE",
      "code_hash": "b90b7a557ea42d0cea739437f307bdb9",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "tensor(0.9544)\ntensor(0.9544)\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "emfo",
      "code_hash": "b986af97de8771c78b2b6d7f034caf64",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "Attention weights: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\nSum: tensor(1.0000)\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "nWHF",
      "code_hash": "01d426fe90a7f1e71cc40ff0f1439ba8",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": []
    },
    {
      "id": "ZHCJ",
      "code_hash": "9b0c68b9ed02b40ee9e41a2a5f733fff",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\nSum: tensor(1.)\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "qnkX",
      "code_hash": "46ee78f8dcf59c377491736e1dc64755",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\nSum: tensor(1.)\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "Vxnm",
      "code_hash": "b10b78de36e39ff699f81a2954584990",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "tensor([0.4419, 0.6515, 0.5683])\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "ecfG",
      "code_hash": "f6580dd1727c68985a22f6638e834747",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "ZBYS",
      "code_hash": "a725b139ea3d9bdedddff16283b461a4",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "nHfw",
      "code_hash": "608f1b575147585791ed731dd36f25f3",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "AjVT",
      "code_hash": "445458740f1514ef2df8a3a72339717b",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "Row 2 sum: 1.0\nAll row sums: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "NCOB",
      "code_hash": "a1fe05bbceaec97ebd020e2ebcdda449",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "tensor([[0.4421, 0.5931, 0.5790],\n        [0.4419, 0.6515, 0.5683],\n        [0.4431, 0.6496, 0.5671],\n        [0.4304, 0.6298, 0.5510],\n        [0.4671, 0.5910, 0.5266],\n        [0.4177, 0.6503, 0.5645]])\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "TRpd",
      "code_hash": "1c9880bf9457187d957fbc550117ca2f",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "Previous 2nd context vector: tensor([0.4419, 0.6515, 0.5683])\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "wlCL",
      "code_hash": "d287737fd5b0281e7d4ba526063d9f1a",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": []
    },
    {
      "id": "wAgl",
      "code_hash": "2cfd47f0efcc4ebf47ed1304b236a81a",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": []
    },
    {
      "id": "dGlV",
      "code_hash": "8a0ab3e2f2061cb981d40528f2f95032",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "tensor([0.4306, 1.4551])\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "lgWD",
      "code_hash": "7e134a8474ea63bd5d14de15a2913e13",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "keys.shape: torch.Size([6, 2])\nvalues.shape: torch.Size([6, 2])\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "fwwy",
      "code_hash": "e0ac41aaeb3878ee9e6d339ebfd03195",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "tensor(1.8524)\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "urSm",
      "code_hash": "79c4c8a1de94c71f29e7a979d5adcebd",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "mWxS",
      "code_hash": "2fbca3f0d4f9861a1165a136de3feaf2",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "YWSi",
      "code_hash": "84d74d9186e3058175dd86fce965c7bf",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "tensor([0.3061, 0.8210])\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "tZnO",
      "code_hash": "fd813f7a49bc8a40cbcd578baa9374c2",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": []
    },
    {
      "id": "CLip",
      "code_hash": "22fb93a91eb5d37f74addf87800a5af5",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "tensor([[0.2996, 0.8053],\n        [0.3061, 0.8210],\n        [0.3058, 0.8203],\n        [0.2948, 0.7939],\n        [0.2927, 0.7891],\n        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "cEAS",
      "code_hash": "96c60e91e0d16427007e35a4e2af54be",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": []
    },
    {
      "id": "EJmg",
      "code_hash": "f60c3691241f0e09c605f83b01c3cbf2",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "tensor([[-0.0739,  0.0713],\n        [-0.0748,  0.0703],\n        [-0.0749,  0.0702],\n        [-0.0760,  0.0685],\n        [-0.0763,  0.0679],\n        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "IpqN",
      "code_hash": "cd842cbe5b737cff15c08229cf06e56b",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "tensor([[0.1921, 0.1646, 0.1652, 0.1550, 0.1721, 0.1510],\n        [0.2041, 0.1659, 0.1662, 0.1496, 0.1665, 0.1477],\n        [0.2036, 0.1659, 0.1662, 0.1498, 0.1664, 0.1480],\n        [0.1869, 0.1667, 0.1668, 0.1571, 0.1661, 0.1564],\n        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.1585],\n        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n       grad_fn=<SoftmaxBackward0>)\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "dlnW",
      "code_hash": "54ba0591bc55a74e73ed905c165099af",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "tensor([[1., 0., 0., 0., 0., 0.],\n        [1., 1., 0., 0., 0., 0.],\n        [1., 1., 1., 0., 0., 0.],\n        [1., 1., 1., 1., 0., 0.],\n        [1., 1., 1., 1., 1., 0.],\n        [1., 1., 1., 1., 1., 1.]])\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "RKFZ",
      "code_hash": "a933b55c5e91dfd6e2e18a78100fdf29",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "tensor([[0.2098, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.1385, 0.2379, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.1390, 0.2369, 0.2326, 0.0000, 0.0000, 0.0000],\n        [0.1435, 0.2074, 0.2046, 0.1462, 0.0000, 0.0000],\n        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.0000],\n        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "IWgg",
      "code_hash": "5999220bcce3b0bff4ac0e1c7d141703",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.3680, 0.6320, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.2284, 0.3893, 0.3822, 0.0000, 0.0000, 0.0000],\n        [0.2046, 0.2956, 0.2915, 0.2084, 0.0000, 0.0000],\n        [0.1753, 0.2250, 0.2269, 0.1570, 0.2158, 0.0000],\n        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "LkGn",
      "code_hash": "b6fcb9fefa5df01ebac9465b12cee6a3",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "tensor([[0.9995,   -inf,   -inf,   -inf,   -inf,   -inf],\n        [0.9544, 1.4950,   -inf,   -inf,   -inf,   -inf],\n        [0.9422, 1.4754, 1.4570,   -inf,   -inf,   -inf],\n        [0.4753, 0.8434, 0.8296, 0.4937,   -inf,   -inf],\n        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654,   -inf],\n        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "woaO",
      "code_hash": "5d3313b0e89b9adfa164412dc0ad3f55",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.4056, 0.5944, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.2566, 0.3741, 0.3693, 0.0000, 0.0000, 0.0000],\n        [0.2176, 0.2823, 0.2796, 0.2205, 0.0000, 0.0000],\n        [0.1826, 0.2178, 0.2191, 0.1689, 0.2115, 0.0000],\n        [0.1473, 0.2033, 0.1996, 0.1500, 0.1160, 0.1839]])\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "VCRE",
      "code_hash": "a52ceb168174043b85cac19d2261b2c6",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "tensor([[2., 2., 0., 2., 2., 0.],\n        [0., 0., 0., 2., 0., 2.],\n        [2., 2., 2., 2., 0., 2.],\n        [0., 2., 2., 0., 0., 2.],\n        [0., 2., 0., 2., 0., 2.],\n        [0., 2., 2., 2., 2., 0.]])\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "PSUk",
      "code_hash": "6628c0ce8df424d1a3c72cf295c6c3a8",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "tensor([[0.4197, 0.4012, 0.0000, 0.2485, 0.2441, 0.0000],\n        [0.0000, 0.0000, 0.0000, 0.2480, 0.0000, 0.3162],\n        [0.2780, 0.4738, 0.4652, 0.2484, 0.0000, 0.3129],\n        [0.0000, 0.4148, 0.4091, 0.0000, 0.0000, 0.3441],\n        [0.0000, 0.3917, 0.0000, 0.2734, 0.0000, 0.2590],\n        [0.0000, 0.4367, 0.4255, 0.2841, 0.1976, 0.0000]])\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "SYQT",
      "code_hash": "c247a774e29f9f681cfbd37259eb5810",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "torch.Size([2, 6, 3])\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "PSQn",
      "code_hash": "2fb96fa912dd5f93e4408015564d621f",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": []
    },
    {
      "id": "lQxp",
      "code_hash": "e7b136ad731c5decb153b4251a64af94",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "tensor([[[-0.4519,  0.2216],\n         [-0.5874,  0.0058],\n         [-0.6300, -0.0632],\n         [-0.5675, -0.0843],\n         [-0.5526, -0.0981],\n         [-0.5299, -0.1081]],\n\n        [[-0.4519,  0.2216],\n         [-0.5874,  0.0058],\n         [-0.6300, -0.0632],\n         [-0.5675, -0.0843],\n         [-0.5526, -0.0981],\n         [-0.5299, -0.1081]]], grad_fn=<UnsafeViewBackward0>)\nbatch.shape=torch.Size([2, 6, 3])\n_context_vecs.shape=torch.Size([2, 6, 2])\nd_in=3, d_out=2\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "WfYj",
      "code_hash": "fc9ba024a0926ae03094b0c442fe0c53",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": []
    },
    {
      "id": "LqFA",
      "code_hash": "d134ae6b30e0ea1ecbb13817b5eddce2",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n         [-0.5874,  0.0058,  0.5891,  0.3257],\n         [-0.6300, -0.0632,  0.6202,  0.3860],\n         [-0.5675, -0.0843,  0.5478,  0.3589],\n         [-0.5526, -0.0981,  0.5321,  0.3428],\n         [-0.5299, -0.1081,  0.5077,  0.3493]],\n\n        [[-0.4519,  0.2216,  0.4772,  0.1063],\n         [-0.5874,  0.0058,  0.5891,  0.3257],\n         [-0.6300, -0.0632,  0.6202,  0.3860],\n         [-0.5675, -0.0843,  0.5478,  0.3589],\n         [-0.5526, -0.0981,  0.5321,  0.3428],\n         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=<CatBackward0>)\nbatch.shape=torch.Size([2, 6, 3])\n_context_vecs.shape=torch.Size([2, 6, 4])\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "MIsd",
      "code_hash": "67e01e5830f6d0c8893c0457ef7302ad",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": []
    },
    {
      "id": "IrqS",
      "code_hash": "2547ff1060a2f35548ccb196faa2f385",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "tensor([[[0.3190, 0.4858],\n         [0.2943, 0.3897],\n         [0.2856, 0.3593],\n         [0.2693, 0.3873],\n         [0.2639, 0.3928],\n         [0.2575, 0.4028]],\n\n        [[0.3190, 0.4858],\n         [0.2943, 0.3897],\n         [0.2856, 0.3593],\n         [0.2693, 0.3873],\n         [0.2639, 0.3928],\n         [0.2575, 0.4028]]], grad_fn=<ViewBackward0>)\ncontext_vecs.shape: torch.Size([2, 6, 2])\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "Lpqv",
      "code_hash": "680e93bc77686ed83720a763ef3e68a5",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "tensor([[[[1.3208, 1.1631, 1.2879],\n          [1.1631, 2.2150, 1.8424],\n          [1.2879, 1.8424, 2.0402]],\n\n         [[0.4391, 0.7003, 0.5903],\n          [0.7003, 1.3737, 1.0620],\n          [0.5903, 1.0620, 0.9912]]]])\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "upgv",
      "code_hash": "ae4d3ffaad860d92855d7acf4f61c8ce",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "First head:\n tensor([[1.3208, 1.1631, 1.2879],\n        [1.1631, 2.2150, 1.8424],\n        [1.2879, 1.8424, 2.0402]])\n\nSecond head:\n tensor([[0.4391, 0.7003, 0.5903],\n        [0.7003, 1.3737, 1.0620],\n        [0.5903, 1.0620, 0.9912]])\n",
          "mimetype": "text/plain"
        }
      ]
    }
  ]
}